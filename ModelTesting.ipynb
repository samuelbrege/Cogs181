{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e74e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import RandomCrop\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import util #For XNOR NIN https://github.com/jiecaoyu/XNOR-Net-PyTorch\n",
    "\n",
    "from binarized_modules import  BinarizeLinear,BinarizeConv2d #For BNN VGG https://github.com/itayhubara/BinaryNet.pytorch\n",
    "from vgg_cifar10_binary import VGG_Cifar10 #For BNN VGG https://github.com/itayhubara/BinaryNet.pytorch\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BinarizedConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n",
    "        self.binary_weight = None\n",
    "\n",
    "    def binarize(self):\n",
    "        self.binary_weight = torch.sign(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.binary_weight is None:\n",
    "            self.binarize()\n",
    "        return F.conv2d(x, self.binary_weight, bias=self.bias, stride=self.stride, padding=self.padding, dilation=self.dilation, groups=self.groups)\n",
    "    \n",
    "class BinarizedActivation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sign(x)\n",
    "    \n",
    "class BinActive(torch.autograd.Function):\n",
    "    '''\n",
    "    Binarize the input activations and calculate the mean across channel dimension.\n",
    "    '''\n",
    "    def forward(self, input):\n",
    "        self.save_for_backward(input)\n",
    "        size = input.size()\n",
    "        mean = torch.mean(input.abs(), 1, keepdim=True)\n",
    "        input = input.sign()\n",
    "        return input, mean\n",
    "\n",
    "    def backward(self, grad_output, grad_output_mean):\n",
    "        input, = self.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input.ge(1)] = 0\n",
    "        grad_input[input.le(-1)] = 0\n",
    "        return grad_input\n",
    "    \n",
    "class XNORConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "            kernel_size=-1, stride=-1, padding=-1, dropout=0):\n",
    "        super(XNORConv2d, self).__init__()\n",
    "        self.layer_type = 'BinConv2d'\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dropout_ratio = dropout\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "        self.bn.weight.data = self.bn.weight.data.zero_().add(1.0)\n",
    "        if dropout!=0:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x, mean = BinActive.apply(x)\n",
    "        if self.dropout_ratio!=0:\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class XnorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XnorNet, self).__init__()\n",
    "        self.xnor = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                XNORConv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                XNORConv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                XNORConv2d( 96, 192, kernel_size=5, stride=1, padding=2, dropout=0.5),\n",
    "                XNORConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                XNORConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                XNORConv2d(192, 192, kernel_size=3, stride=1, padding=1, dropout=0.5),\n",
    "                XNORConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                if hasattr(m.weight, 'data'):\n",
    "                    m.weight.data.clamp_(min=0.01)\n",
    "        x = self.xnor(x)\n",
    "        x = x.view(x.size(0), 10)\n",
    "        return x\n",
    "\n",
    "class FPBlinkNet(nn.Module):\n",
    "    def __init__(self,dropout_prob=0.5,l1_reg=0.0082):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.res1 = SimpleResidualBlock(32, 32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.res2 = SimpleResidualBlock(64, 64)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.res3 = SimpleResidualBlock(128, 128)\n",
    "        self.fc = nn.Linear(8192, 10)\n",
    "        self.max_train_acc = 0.0\n",
    "        self.l1_reg=l1_reg\n",
    "        #self.lr = lr\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "    def update_max_train_acc(self, acc):\n",
    "        if acc > self.max_train_acc:\n",
    "            self.max_train_acc = acc\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.res3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out \n",
    "    \n",
    "class BlinkNet(nn.Module):\n",
    "    def __init__(self,dropout_prob=0.45,l1_reg=0.000345, lr=0.00008):\n",
    "        super().__init__()\n",
    "        self.conv1 = BinarizedConv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.res1 = SimpleResidualBlock(32, 32)\n",
    "        self.conv2 = BinarizedConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.res2 = SimpleResidualBlock(64, 64)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "        self.conv3 = BinarizedConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.res3 = SimpleResidualBlock(128, 128)\n",
    "        self.fc = nn.Linear(8192, 10)\n",
    "        self.max_train_acc = 0.0\n",
    "        self.l1_reg=l1_reg\n",
    "        self.lr = lr\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "    def update_max_train_acc(self, acc):\n",
    "        if acc > self.max_train_acc:\n",
    "            self.max_train_acc = acc\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.res3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "class SimpleResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        return self.relu2(out) + x # ReLU can be applied before or after adding the input\n",
    "\n",
    "class BinaryBlinkNet(nn.Module):\n",
    "    def __init__(self,dropout_prob=0.45,l1_reg=0.000345, lr=0.00008):\n",
    "        super().__init__()\n",
    "        self.conv1 = BinarizedConv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.res1 = BinarizedResidualBlock(32, 32)\n",
    "        self.conv2 = BinarizeConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.res2 = BinarizedResidualBlock(64, 64)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "        self.conv3 = BinarizedConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.res3 = BinarizedResidualBlock(128, 128)\n",
    "        self.fc = nn.Linear(8192, 10)\n",
    "        self.max_train_acc = 0.0\n",
    "        self.l1_reg=l1_reg\n",
    "        self.lr = lr\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "    def update_max_train_acc(self, acc):\n",
    "        if acc > self.max_train_acc:\n",
    "            self.max_train_acc = acc\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.res3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "class BinarizedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = BinarizedConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = BinarizedConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        return self.relu2(out) + x # ReLU can be applied before or after adding the input\n",
    "\n",
    "\n",
    "\n",
    "#Training function    \n",
    "def train(train_dl, val_dl, model, loss_fn, optimizer, epochs, history=6, file_name='best_model.pth'):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    BVE=[]\n",
    "    epoch_mem_usage=[]\n",
    "    memory_usage=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        #print(\"Model Lr:\", model.lr)\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        best_val_acc=0\n",
    "        best_epoch=0\n",
    "        t=0\n",
    "        for i, (images, labels) in enumerate(train_dl):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_mem_usage = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "            memory_usage.append(current_mem_usage)\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            \n",
    "            \n",
    "        train_loss /= len(train_dl.dataset)\n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = evaluate(model, val_dl, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "            BVE=[val_acc,epoch]\n",
    "        epoch_mem_usage.append(sum(memory_usage))\n",
    "        memory_usage=[]\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}, Epoch Memory Usage: {epoch_mem_usage[epoch]:.4f} MB')      \n",
    "        \n",
    "    return train_losses, val_losses, train_accs, val_accs,BVE,epoch_mem_usage\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        val_loss /= len(data_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d8b01",
   "metadata": {},
   "source": [
    "Below are cells for running the models. Here we've run just 1 epoch of each model just to show everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b3b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Data setup\n",
    "\n",
    "import time\n",
    "\n",
    "#Epochs low just to make sure things work\n",
    "num_epochs = 1\n",
    "\n",
    "#Data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_dataset =CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Create the model and move it to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccfe860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Training Loss: 0.0148, Training Accuracy: 0.3092, Validation Loss: 0.0129, Validation Accuracy: 0.3977, Epoch Memory Usage: 4095.0068 MB\n",
      "Test accuracy: 0.3977\n",
      "Train accuracy: 0.3896\n",
      "Training process took 71.07526659965515 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "b_start_time = time.time()\n",
    "#Change this depending on model\n",
    "model = BlinkNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "binary_criterion = nn.CrossEntropyLoss()\n",
    "binary_optimizer = optim.Adam(model.parameters(), lr=0.0000778)\n",
    "\n",
    "binary_train_losses, binary_train_val_losses, binary_train_accs, binary_train_val_accs,binary_BVE,binary_mem_usage = train(train_loader, test_loader, model, binary_criterion, binary_optimizer, num_epochs, file_name='BlinkNet.pth')\n",
    "binary_train_acc = get_accuracy(model, train_loader)\n",
    "binary_test_accuracy = get_accuracy(model, test_loader)\n",
    "b_end_time = time.time()\n",
    "print(f'Test accuracy: {binary_test_accuracy:.4f}')\n",
    "print(f'Train accuracy: {binary_train_acc:.4f}')\n",
    "print(f\"Training process took {b_end_time - b_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9514bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Training Loss: 0.0142, Training Accuracy: 0.3361, Validation Loss: 0.0118, Validation Accuracy: 0.4517, Epoch Memory Usage: 3956.2095 MB\n",
      "Test accuracy: 0.4517\n",
      "Train accuracy: 0.4292\n",
      "Training process took 61.24358129501343 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "b_start_time = time.time()\n",
    "#Change this depending on model\n",
    "model = FPBlinkNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "binary_criterion = nn.CrossEntropyLoss()\n",
    "binary_optimizer = optim.Adam(model.parameters(), lr=0.0000778)\n",
    "\n",
    "binary_train_losses, binary_train_val_losses, binary_train_accs, binary_train_val_accs,binary_BVE,binary_mem_usage = train(train_loader, test_loader, model, binary_criterion, binary_optimizer, num_epochs, file_name='FPBlinkNet.pth')\n",
    "binary_train_acc = get_accuracy(model, train_loader)\n",
    "binary_test_accuracy = get_accuracy(model, test_loader)\n",
    "b_end_time = time.time()\n",
    "print(f'Test accuracy: {binary_test_accuracy:.4f}')\n",
    "print(f'Train accuracy: {binary_train_acc:.4f}')\n",
    "print(f\"Training process took {b_end_time - b_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d45ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Training Loss: 1.2008, Training Accuracy: 0.1382, Validation Loss: 0.5814, Validation Accuracy: 0.2204, Epoch Memory Usage: 4672.5337 MB\n",
      "Test accuracy: 0.2204\n",
      "Train accuracy: 0.2050\n",
      "Training process took 59.75531601905823 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "b_start_time = time.time()\n",
    "#Change this depending on model\n",
    "model = BinaryBlinkNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "binary_criterion = nn.CrossEntropyLoss()\n",
    "binary_optimizer = optim.Adam(model.parameters(), lr=0.0000778)\n",
    "\n",
    "binary_train_losses, binary_train_val_losses, binary_train_accs, binary_train_val_accs,binary_BVE,binary_mem_usage = train(train_loader, test_loader, model, binary_criterion, binary_optimizer, num_epochs, file_name='BinaryBlinkNet.pth')\n",
    "binary_train_acc = get_accuracy(model, train_loader)\n",
    "binary_test_accuracy = get_accuracy(model, test_loader)\n",
    "b_end_time = time.time()\n",
    "print(f'Test accuracy: {binary_test_accuracy:.4f}')\n",
    "print(f'Train accuracy: {binary_train_acc:.4f}')\n",
    "print(f\"Training process took {b_end_time - b_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2b125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Training Loss: 0.0154, Training Accuracy: 0.4839, Validation Loss: 0.0087, Validation Accuracy: 0.6737, Epoch Memory Usage: 8321.7397 MB\n",
      "Test accuracy: 0.6737\n",
      "Train accuracy: 0.5640\n",
      "Training process took 66.16460490226746 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "b_start_time = time.time()\n",
    "#Change this depending on model\n",
    "model = XnorNet().to(device)\n",
    "pretrained_model = torch.load(\"nin.best.pth.tar\")\n",
    "best_acc = pretrained_model['best_acc']\n",
    "model.load_state_dict(pretrained_model['state_dict'])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "binary_criterion = nn.CrossEntropyLoss()\n",
    "binary_optimizer = optim.Adam(model.parameters(), lr=0.0000778)\n",
    "\n",
    "binary_train_losses, binary_train_val_losses, binary_train_accs, binary_train_val_accs,binary_BVE,binary_mem_usage = train(train_loader, test_loader, model, binary_criterion, binary_optimizer, num_epochs, file_name='XNORkNet.pth')\n",
    "binary_train_acc = get_accuracy(model, train_loader)\n",
    "binary_test_accuracy = get_accuracy(model, test_loader)\n",
    "b_end_time = time.time()\n",
    "print(f'Test accuracy: {binary_test_accuracy:.4f}')\n",
    "print(f'Train accuracy: {binary_train_acc:.4f}')\n",
    "print(f\"Training process took {b_end_time - b_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e3e8718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Training Loss: 0.0577, Training Accuracy: 0.0011, Validation Loss: 0.0586, Validation Accuracy: 0.0006, Epoch Memory Usage: 283589.7031 MB\n",
      "Test accuracy: 0.0006\n",
      "Train accuracy: 0.0010\n",
      "Training process took 110.6307201385498 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "b_start_time = time.time()\n",
    "#Change this depending on model\n",
    "model = VGG_Cifar10().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "binary_criterion = nn.CrossEntropyLoss()\n",
    "binary_optimizer = optim.Adam(model.parameters(), lr=0.0000778)\n",
    "\n",
    "binary_train_losses, binary_train_val_losses, binary_train_accs, binary_train_val_accs,binary_BVE,binary_mem_usage = train(train_loader, test_loader, model, binary_criterion, binary_optimizer, num_epochs, file_name='BNNVGG.pth')\n",
    "binary_train_acc = get_accuracy(model, train_loader)\n",
    "binary_test_accuracy = get_accuracy(model, test_loader)\n",
    "b_end_time = time.time()\n",
    "print(f'Test accuracy: {binary_test_accuracy:.4f}')\n",
    "print(f'Train accuracy: {binary_train_acc:.4f}')\n",
    "print(f\"Training process took {b_end_time - b_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbefd5",
   "metadata": {},
   "source": [
    "Below cell is for checking memory usage. We tried out multiple methods but max_memory_allocated() seemed the most reliable and accurate. Makes use of model trained above. If you just want to find memory usage without extensive model training, make sure to run model for at least a couple epochs to initialize everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c19f3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1\n",
      "Files already downloaded and verified\n",
      "H2\n",
      "0 386.86279296875 2328.977294921875\n",
      "Average time per batch: 2328.977 ms\n",
      "Average memory usage: 386.863 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "#Repetitions used for official stats is 500\n",
    "repetitions = 1\n",
    "timings=np.zeros((repetitions,1))\n",
    "memory_usage = np.zeros(repetitions)\n",
    "# GPU warm-up\n",
    "print(\"g1\")\n",
    "for _ in range(10):\n",
    "    _ = model(dummy_input)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "print(\"H2\")\n",
    "# Measure performance\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "        starter.record()\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #flops = FlopCountAnalysis(model, inputs)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "        curr_mem = torch.cuda.max_memory_allocated()\n",
    "        memory_usage[rep] = curr_mem / 1024 / 1024  # convert bytes to megabytes\n",
    "        print(rep, memory_usage[rep], curr_time)\n",
    "\n",
    "mean_time = np.sum(timings) / repetitions\n",
    "std_time = np.std(timings)\n",
    "mean_memory = np.sum(memory_usage) / repetitions\n",
    "std_memory = np.std(memory_usage)\n",
    "\n",
    "#Memory changes based on GPU instance\n",
    "print(\"Average time per batch: {:.3f} ms\".format(mean_time))\n",
    "print(\"Average memory usage: {:.3f} MB\".format(mean_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8cd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "mem_usage_resnet=np.array(memory_usage)\n",
    "np.savetxt('mem_usage.csv', mem_usage_resnet, delimiter=',')\n",
    "time_usage_resnet=np.array(timings)\n",
    "np.savetxt('time_usage.csv', timings, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
